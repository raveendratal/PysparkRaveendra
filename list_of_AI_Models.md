# ğŸ¤– AI Model Performance & Pricing Index
This document compares leading AI models across intelligence, price, generation speed, and latency for cost, throughput, and responsiveness trade-offs in production systems.

---

## Columns
- Model â€“ Model name & version
- Creator â€“ Company/organization
- Context Window â€“ Max tokens supported
- Intelligence Index â€“ Benchmark-based capability score
- Price (USD / 1M tokens) â€“ Blended price
- Output Tokens/s (Median) â€“ Generation throughput
- Latency â€“ First Chunk (s) â€“ Delay to first token

---

## AI21 Labs
| Model | Creator | Context Window | Intelligence Index | Price (USD / 1M tokens) | Output Tokens/s (Median) | Latency â€“ First Chunk (s) |
|---|---|---:|---:|---:|---:|---:|
| ğŸŸ© Jamba 1.7 Large | ğŸ§  AI21 Labs | 256k | 21 | $3.50 | 46.8 | 0.80 |
| ğŸŸ¦ Jamba 1.7 Mini | ğŸ§  AI21 Labs | 258k | 4 | $0.25 | 139.3 | 0.66 |

## Alibaba
| Model | Creator | Context Window | Intelligence Index | Price (USD / 1M tokens) | Output Tokens/s (Median) | Latency â€“ First Chunk (s) |
|---|---|---:|---:|---:|---:|---:|
| ğŸŸ¥ Qwen3 235B 2507 | ğŸ¢ Alibaba | 256k | 57 | $2.63 | 52.6 | 1.15 |
| ğŸŸ¥ Qwen3 30B 2507 | ğŸ¢ Alibaba | 262k | 46 | $0.75 | 100.3 | 1.00 |
| ğŸŸ¥ Qwen3 235B 2507 | ğŸ¢ Alibaba | 256k | 45 | $1.23 | 34.4 | 1.11 |
| ğŸŸ¥ Qwen3 4B 2507 | ğŸ¢ Alibaba | 262k | 43 | $0.00 | 0.0 | 0.00 |
| ğŸŸ¥ Qwen3 Coder 480B | ğŸ¢ Alibaba | 262k | 42 | $3.00 | 42.3 | 1.56 |
| ğŸŸ¥ QwQ-32B | ğŸ¢ Alibaba | 131k | 38 | $0.74 | 47.5 | 0.61 |
| ğŸŸ¥ Qwen3 30B 2507 | ğŸ¢ Alibaba | 262k | 37 | $0.35 | 87.3 | 0.96 |
| ğŸŸ¥ Qwen3 Coder 30B | ğŸ¢ Alibaba | 262k | 33 | $0.90 | 92.2 | 1.46 |

## Amazon
| Model | Creator | Context Window | Intelligence Index | Price (USD / 1M tokens) | Output Tokens/s (Median) | Latency â€“ First Chunk (s) |
|---|---|---:|---:|---:|---:|---:|
| ğŸŸ§ Nova Premier | ğŸŸ  Amazon | 1m | 31 | $5.00 | 74.4 | 0.88 |

## Anthropic
| Model | Creator | Context Window | Intelligence Index | Price (USD / 1M tokens) | Output Tokens/s (Median) | Latency â€“ First Chunk (s) |
|---|---|---:|---:|---:|---:|---:|
| ğŸŸ£ Claude 4.1 Opus | ğŸŸª Anthropic | 200k | 59 | $30.00 | 46.3 | 1.55 |
| ğŸŸ£ Claude 4 Sonnet | ğŸŸª Anthropic | 1m | 57 | $6.00 | 51.5 | 1.13 |
| ğŸŸ£ Claude 4 Opus | ğŸŸª Anthropic | 200k | 54 | $30.00 | 52.2 | 1.57 |
| ğŸŸ£ Claude 4.1 Opus | ğŸŸª Anthropic | 200k | 45 | $30.00 | 45.2 | 1.57 |
| ğŸŸ£ Claude 4 Sonnet | ğŸŸª Anthropic | 1m | 44 | $6.00 | 76.2 | 1.25 |
| ğŸŸ£ Claude 4 Opus | ğŸŸª Anthropic | 200k | 42 | $30.00 | 52.2 | 1.95 |

## Cohere
| Model | Creator | Context Window | Intelligence Index | Price (USD / 1M tokens) | Output Tokens/s (Median) | Latency â€“ First Chunk (s) |
|---|---|---:|---:|---:|---:|---:|
| ğŸŸ¤ Command A | ğŸ”¶ Cohere | 256k | 28 | $4.38 | 94.0 | 0.18 |
| ğŸŸ¤ Aya Expanse 32B | ğŸ”¶ Cohere | 128k | 6 | $0.75 | 69.5 | 0.12 |
| ğŸŸ¤ Aya Expanse 8B | ğŸ”¶ Cohere | 8k | 2 | $0.75 | 81.0 | 0.19 |

## DeepSeek
| Model | Creator | Context Window | Intelligence Index | Price (USD / 1M tokens) | Output Tokens/s (Median) | Latency â€“ First Chunk (s) |
|---|---|---:|---:|---:|---:|---:|
| âš« DeepSeek V3.1 | âš™ï¸ DeepSeek | 128k | 54 | $0.96 | 20.1 | 2.89 |
| âš« DeepSeek R1 0528 | âš™ï¸ DeepSeek | 128k | 52 | $0.96 | 20.5 | 2.84 |
| âš« DeepSeek V3.1 | âš™ï¸ DeepSeek | 128k | 45 | $0.48 | 19.8 | 2.83 |
| âš« DeepSeek R1 0528 Qwen3 8B | âš™ï¸ DeepSeek | 33k | 35 | $0.07 | 54.5 | 0.72 |

## Google (Gemini + Gemma)
| Model | Creator | Context Window | Intelligence Index | Price (USD / 1M tokens) | Output Tokens/s (Median) | Latency â€“ First Chunk (s) |
|---|---|---:|---:|---:|---:|---:|
| ğŸ”µ Gemini 2.5 Pro | ğŸ”µ Google | 1m | 60 | $3.44 | 152.9 | 28.39 |
| ğŸ”µ Gemini 2.5 Flash | ğŸ”µ Google | 1m | 51 | $0.85 | 255.7 | 11.28 |
| ğŸ”µ Gemini 2.5 Flash | ğŸ”µ Google | 1m | 40 | $0.85 | 227.9 | 0.31 |
| ğŸ”µ Gemini 2.5 Flash-Lite | ğŸ”µ Google | 1m | 40 | $0.17 | 540.3 | 7.69 |
| ğŸ”µ Gemini 2.5 Flash-Lite | ğŸ”µ Google | 1m | 30 | $0.17 | 352.3 | 0.23 |
| ğŸ”· Gemma 3 27B | ğŸ”· Google | 128k | 22 | $0.00 | 47.1 | 0.63 |
| ğŸ”· Gemma 3 12B | ğŸ”· Google | 128k | 21 | $0.23 | 0.0 | 0.00 |
| ğŸ”· Gemma 3n E4B | ğŸ”· Google | 32k | 16 | $0.03 | 72.9 | 0.33 |
| ğŸ”· Gemma 3 4B | ğŸ”· Google | 128k | 15 | $0.03 | 0.0 | 0.00 |
| ğŸ”· Gemma 3n E2B | ğŸ”· Google | 32k | 8 | $0.00 | 43.1 | 0.32 |
| ğŸ”· Gemma 3 1B | ğŸ”· Google | 32k | 6 | $0.00 | 0.0 | 0.00 |

## IBM
| Model | Creator | Context Window | Intelligence Index | Price (USD / 1M tokens) | Output Tokens/s (Median) | Latency â€“ First Chunk (s) |
|---|---|---:|---:|---:|---:|---:|
| âšª Granite 3.3 8B | âšª IBM | 128k | 15 | $0.09 | 109.9 | 0.41 |

## LG AI Research
| Model | Creator | Context Window | Intelligence Index | Price (USD / 1M tokens) | Output Tokens/s (Median) | Latency â€“ First Chunk (s) |
|---|---|---:|---:|---:|---:|---:|
| ğŸŸ© EXAONE 4.0 32B | ğŸ§© LG AI Research | 131k | 43 | $0.70 | 77.0 | 0.30 |
| ğŸŸ© EXAONE 4.0 32B | ğŸ§© LG AI Research | 131k | 33 | $0.70 | 68.2 | 0.33 |
| ğŸŸ© Exaone 4.0 1.2B | ğŸ§© LG AI Research | 64k | 27 | $0.00 | 0.0 | 0.00 |
| ğŸŸ© Exaone 4.0 1.2B | ğŸ§© LG AI Research | 64k | 20 | $0.00 | 0.0 | 0.00 |

## Liquid AI
| Model | Creator | Context Window | Intelligence Index | Price (USD / 1M tokens) | Output Tokens/s (Median) | Latency â€“ First Chunk (s) |
|---|---|---:|---:|---:|---:|---:|
| ğŸ”µ LFM2 1.2B | ğŸ’§ Liquid AI | 33k | 8 | $0.00 | 0.0 | 0.00 |

## Meta
| Model | Creator | Context Window | Intelligence Index | Price (USD / 1M tokens) | Output Tokens/s (Median) | Latency â€“ First Chunk (s) |
|---|---|---:|---:|---:|---:|---:|
| ğŸŸª Llama 4 Maverick | ğŸ¦™ Meta | 1m | 36 | $0.39 | 143.8 | 0.34 |
| ğŸ¦™ Llama 4 Scout | ğŸ¦™ Meta | 10m | 28 | $0.26 | 115.5 | 0.37 |
| ğŸ¦™ Llama 3.3 70B | ğŸ¦™ Meta | 128k | 28 | $0.60 | 85.2 | 0.45 |
| ğŸ¦™ Llama 3.1 405B | ğŸ¦™ Meta | 128k | 26 | $3.75 | 31.7 | 0.75 |
| ğŸ¦™ Llama 3.2 90B (Vision) | ğŸ¦™ Meta | 128k | 19 | $0.72 | 30.5 | 0.37 |
| ğŸ¦™ Llama 3.2 11B (Vision) | ğŸ¦™ Meta | 128k | 15 | $0.16 | 72.2 | 0.39 |

## Microsoft Azure
| Model | Creator | Context Window | Intelligence Index | Price (USD / 1M tokens) | Output Tokens/s (Median) | Latency â€“ First Chunk (s) |
|---|---|---:|---:|---:|---:|---:|
| ğŸ”· Phi-4 | ğŸ–¥ï¸ Microsoft Azure | 16k | 25 | $0.22 | 29.8 | 0.46 |
| ğŸ”· Phi-4 Multimodal | ğŸ–¥ï¸ Microsoft Azure | 128k | 12 | $0.00 | 18.2 | 0.36 |

## MiniMax
| Model | Creator | Context Window | Intelligence Index | Price (USD / 1M tokens) | Output Tokens/s (Median) | Latency â€“ First Chunk (s) |
|---|---|---:|---:|---:|---:|---:|
| â¬› MiniMax M1 80k | âš¡ MiniMax | 1m | 46 | $0.82 | 0.0 | 0.00 |
| â¬› MiniMax M1 40k | âš¡ MiniMax | 1m | 42 | $0.82 | 0.0 | 0.00 |
| â¬› MiniMax-Text-01 | âš¡ MiniMax | 4m | 26 | $0.42 | 0.0 | 0.00 |

## Mistral
| Model | Creator | Context Window | Intelligence Index | Price (USD / 1M tokens) | Output Tokens/s (Median) | Latency â€“ First Chunk (s) |
|---|---|---:|---:|---:|---:|---:|
| ğŸ”º Mistral Medium 3.1 | ğŸ”º Mistral | 128k | 35 | $0.80 | 48.8 | 0.41 |
| ğŸ”º Mistral Medium 3 | ğŸ”º Mistral | 128k | 35 | $0.80 | 67.7 | 0.43 |
| ğŸ”º Magistral Medium | ğŸ”º Mistral | 40k | 34 | $2.75 | 144.2 | 0.39 |
| ğŸ”º Magistral Small | ğŸ”º Mistral | 40k | 32 | $0.75 | 179.6 | 0.32 |
| ğŸ”º Mistral Small 3.2 | ğŸ”º Mistral | 128k | 29 | $0.15 | 144.5 | 0.28 |
| ğŸ”º Devstral Medium | ğŸ”º Mistral | 256k | 28 | $0.80 | 101.1 | 0.38 |
| ğŸ”º Devstral Small | ğŸ”º Mistral | 256k | 18 | $0.15 | 145.4 | 0.33 |
| ğŸ”º Codestral (Jan) | ğŸ”º Mistral | 256k | 13 | $0.45 | 152.6 | 0.30 |
| ğŸ”º Ministral 8B | ğŸ”º Mistral | 128k | 8 | $0.10 | 175.8 | 0.30 |
| ğŸ”º Ministral 3B | ğŸ”º Mistral | 128k | 5 | $0.04 | 248.1 | 0.29 |

## Moonshot AI
| Model | Creator | Context Window | Intelligence Index | Price (USD / 1M tokens) | Output Tokens/s (Median) | Latency â€“ First Chunk (s) |
|---|---|---:|---:|---:|---:|---:|
| ğŸŒ™ Kimi K2 0905 | ğŸŒ™ Moonshot AI | 256k | 50 | $1.35 | 55.1 | 0.48 |
| ğŸŒ™ Kimi K2 | ğŸŒ™ Moonshot AI | 128k | 48 | $1.07 | 54.1 | 0.50 |

## Nous Research
| Model | Creator | Context Window | Intelligence Index | Price (USD / 1M tokens) | Output Tokens/s (Median) | Latency â€“ First Chunk (s) |
|---|---|---:|---:|---:|---:|---:|
| ğŸŸ£ Hermes 4 - Llama-3.1 70B | ğŸ§  Nous Research | 128k | 39 | $0.20 | 82.8 | 0.59 |
| ğŸŸ£ Hermes 4 405B | ğŸ§  Nous Research | 128k | 33 | $1.50 | 31.9 | 0.70 |
| ğŸŸ£ Hermes 4 70B | ğŸ§  Nous Research | 128k | 24 | $0.20 | 75.7 | 0.58 |
| ğŸŸ£ DeepHermes 3 - Mistral 24B | ğŸ§  Nous Research | 32k | 16 | $0.00 | 0.0 | 0.00 |
| ğŸŸ£ DeepHermes 3 - Llama-3.1 8B | ğŸ§  Nous Research | 128k | 2 | $0.00 | 0.0 | 0.00 |

## NVIDIA
| Model | Creator | Context Window | Intelligence Index | Price (USD / 1M tokens) | Output Tokens/s (Median) | Latency â€“ First Chunk (s) |
|---|---|---:|---:|---:|---:|---:|
| ğŸŸ¢ Llama Nemotron Super 49B v1.5 | ğŸŸ© NVIDIA | 128k | 45 | $0.00 | 0.0 | 0.00 |
| ğŸŸ¢ Llama Nemotron Ultra | ğŸŸ© NVIDIA | 128k | 38 | $0.90 | 37.5 | 0.71 |
| ğŸŸ¢ NVIDIA Nemotron Nano 9B V2 | ğŸŸ© NVIDIA | 131k | 38 | $0.00 | 0.0 | 0.00 |
| ğŸŸ¢ NVIDIA Nemotron Nano 9B V2 | ğŸŸ© NVIDIA | 131k | 37 | $0.00 | 0.0 | 0.00 |
| ğŸŸ¢ Llama 3.3 Nemotron Super 49B | ğŸŸ© NVIDIA | 128k | 35 | $0.00 | 0.0 | 0.00 |
| ğŸŸ¢ Llama Nemotron Super 49B v1.5 | ğŸŸ© NVIDIA | 128k | 27 | $0.00 | 0.0 | 0.00 |
| ğŸŸ¢ Llama 3.1 Nemotron Nano 4B v1.1 | ğŸŸ© NVIDIA | 128k | 26 | $0.00 | 0.0 | 0.00 |
| ğŸŸ¢ Llama 3.3 Nemotron Super 49B v1 | ğŸŸ© NVIDIA | 128k | 26 | $0.00 | 0.0 | 0.00 |
| ğŸŸ¢ Llama 3.1 Nemotron 70B | ğŸŸ© NVIDIA | 128k | 23 | $0.17 | 32.2 | 0.56 |

## OpenAI
| Model | Creator | Context Window | Intelligence Index | Price (USD / 1M tokens) | Output Tokens/s (Median) | Latency â€“ First Chunk (s) |
|---|---|---:|---:|---:|---:|---:|
| ğŸ¤– GPT-5 (high) | ğŸ§­ OpenAI | 400k | 67 | $3.44 | 61.9 | 72.53 |
| ğŸ¤– GPT-5 (medium) | ğŸ§­ OpenAI | 400k | 66 | $3.44 | 177.3 | 30.76 |
| ğŸ¤– o3-pro | ğŸ§­ OpenAI | 200k | 65 | $35.00 | 20.1 | 127.04 |
| ğŸ¤– o3 | ğŸ§­ OpenAI | 200k | 65 | $3.50 | 187.1 | 12.32 |
| ğŸ¤– GPT-5 mini (high) | ğŸ§­ OpenAI | 400k | 62 | $0.69 | 76.7 | 99.19 |
| ğŸ¤– GPT-5 (low) | ğŸ§­ OpenAI | 400k | 62 | $3.44 | 150.9 | 14.41 |
| ğŸ¤– GPT-5 mini (medium) | ğŸ§­ OpenAI | 400k | 61 | $0.69 | 73.7 | 27.82 |
| ğŸ¤– o4-mini (high) | ğŸ§­ OpenAI | 200k | 59 | $1.93 | 107.9 | 39.30 |
| ğŸ¤– gpt-oss-120B (high) | ğŸ§­ OpenAI | 131k | 58 | $0.26 | 226.5 | 0.44 |
| ğŸ¤– o3-mini (high) | ğŸ§­ OpenAI | 200k | 51 | $1.93 | 141.7 | 41.54 |
| ğŸ¤– GPT-5 nano (high) | ğŸ§­ OpenAI | 400k | 49 | $0.14 | 122.8 | 67.06 |
| ğŸ¤– o3-mini | ğŸ§­ OpenAI | 200k | 48 | $1.93 | 149.3 | 12.46 |
| ğŸ¤– GPT-5 nano (medium) | ğŸ§­ OpenAI | 400k | 48 | $0.14 | 196.2 | 31.93 |
| ğŸ¤– gpt-oss-20B (high) | ğŸ§­ OpenAI | 131k | 45 | $0.09 | 255.5 | 0.52 |
| ğŸ¤– GPT-5 (minimal) | ğŸ§­ OpenAI | 400k | 43 | $3.44 | 134.0 | 1.05 |
| ğŸ¤– GPT-4.1 | ğŸ§­ OpenAI | 1m | 43 | $3.50 | 105.5 | 0.51 |
| ğŸ¤– GPT-4.1 mini | ğŸ§­ OpenAI | 1m | 42 | $0.70 | 70.5 | 0.45 |
| ğŸ¤– GPT-5 mini (minimal) | ğŸ§­ OpenAI | 400k | 42 | $0.69 | 73.1 | 0.98 |
| ğŸ¤– GPT-5 nano (minimal) | ğŸ§­ OpenAI | 400k | 29 | $0.14 | 209.0 | 0.85 |
| ğŸ¤– GPT-4.1 nano | ğŸ§­ OpenAI | 1m | 27 | $0.17 | 108.5 | 0.40 |
| ğŸ¤– GPT-4o (ChatGPT) | ğŸ§­ OpenAI | 128k | 25 | $7.50 | 0.0 | 0.00 |
| ğŸ¤– GPT-4o mini | ğŸ§­ OpenAI | 128k | 21 | $0.26 | 62.1 | 0.52 |

## Perplexity
| Model | Creator | Context Window | Intelligence Index | Price (USD / 1M tokens) | Output Tokens/s (Median) | Latency â€“ First Chunk (s) |
|---|---|---:|---:|---:|---:|---:|
| ğŸŸ£ R1 1776 | ğŸŒ€ Perplexity | 128k | 19 | $3.50 | 0.0 | 0.00 |

## Reka AI
| Model | Creator | Context Window | Intelligence Index | Price (USD / 1M tokens) | Output Tokens/s (Median) | Latency â€“ First Chunk (s) |
|---|---|---:|---:|---:|---:|---:|
| ğŸŸ  Reka Flash 3 | ğŸ”¶ Reka AI | 128k | 33 | $0.35 | 50.9 | 1.31 |

## Upstage
| Model | Creator | Context Window | Intelligence Index | Price (USD / 1M tokens) | Output Tokens/s (Median) | Latency â€“ First Chunk (s) |
|---|---|---:|---:|---:|---:|---:|
| ğŸŸ¡ Solar Pro 2 | â˜€ï¸ Upstage | 66k | 38 | $0.50 | 104.3 | 1.39 |
| ğŸŸ¡ Solar Pro 2 | â˜€ï¸ Upstage | 66k | 30 | $0.50 | 107.1 | 1.39 |

## xAI
| Model | Creator | Context Window | Intelligence Index | Price (USD / 1M tokens) | Output Tokens/s (Median) | Latency â€“ First Chunk (s) |
|---|---|---:|---:|---:|---:|---:|
| ğŸŸ¤ Grok 4 | âš¡ xAI | 256k | 65 | $6.00 | 49.0 | 11.64 |
| ğŸŸ¤ Grok 3 mini Reasoning (high) | âš¡ xAI | 1m | 57 | $0.35 | 99.3 | 0.61 |
| ğŸŸ¤ Grok Code Fast 1 | âš¡ xAI | 256k | 49 | $0.53 | 300.3 | 6.49 |
| ğŸŸ¤ Grok 3 Reasoning Beta | âš¡ xAI | 1m | 41 | $0.00 | 0.0 | 0.00 |
| ğŸŸ¤ Grok 3 | âš¡ xAI | 1m | 36 | $6.00 | 51.3 | 0.69 |
| ğŸŸ¤ Grok 3 mini Reasoning (low) | âš¡ xAI | 1m | â€” | $0.35 | 62.0 | 0.57 |

## Z AI
| Model | Creator | Context Window | Intelligence Index | Price (USD / 1M tokens) | Output Tokens/s (Median) | Latency â€“ First Chunk (s) |
|---|---|---:|---:|---:|---:|---:|
| ğŸŸ© GLM-4.5 | ğŸ§¾ Z AI | 128k | 49 | $0.97 | 57.5 | 0.65 |
| ğŸŸ© GLM-4.5-Air | ğŸ§¾ Z AI | 128k | 48 | $0.42 | 99.8 | 0.98 |
| ğŸŸ© GLM-4.5V | ğŸ§¾ Z AI | 64k | 39 | $0.90 | 94.8 | 0.78 |
| ğŸŸ© GLM-4.5V | ğŸ§¾ Z AI | 64k | 26 | $0.90 | 88.5 | 0.70 |

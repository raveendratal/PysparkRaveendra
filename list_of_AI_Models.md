# ğŸ¤– AI Model Performance & Pricing Index
Comparison of 100+ AI models across providers.  
Metrics: ğŸ’¡ Intelligence, ğŸ’° Price, âš¡ Speed, â±ï¸ Latency.  
Use this as a reference for **FinTech SaaS, ML infra, and production deployments**. 
***
## ğŸ“‘ Columns Explained
- ğŸ“Œ **Model** â€“ Model name & version  
- ğŸ¢ **Creator** â€“ Company/organization  
- ğŸ“ **Context Window** â€“ Max tokens supported  
- ğŸ’¡ **Intelligence Index** â€“ Benchmark-based capability score  
- ğŸ’° **Price (USD / 1M tokens)** â€“ Cost efficiency  
- âš¡ **Output Tokens/s (Median)** â€“ Generation throughput  
- â±ï¸ **Latency â€“ First Chunk (s)** â€“ Response delay for first token  
***

### ğŸ§  AI21 Labs
| Model ğŸ” | Context Window ğŸ“ | Intelligence ğŸ’¡ | Price ğŸ’° (USD/1M) | Speed âš¡ (Tokens/s) | Latency â±ï¸ (s) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| Jamba 1.7 Large | 256k | 21 | **$3.50** | 46.8 | 0.80 |
| Jamba 1.7 Mini | 258k | 4 | **$0.25** | 139.3 | 0.66 |

### ğŸ¢ Alibaba
| Model ğŸ” | Context Window ğŸ“ | Intelligence ğŸ’¡ | Price ğŸ’° (USD/1M) | Speed âš¡ (Tokens/s) | Latency â±ï¸ (s) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| Qwen3 235B 2507 | 256k | 57 | **$2.63** | 52.6 | 1.15 |
| Qwen3 30B 2507 | 262k | 46 | **$0.75** | 100.3 | 1.00 |
| Qwen3 235B 2507 | 256k | 45 | **$1.23** | 34.4 | 1.11 |
| Qwen3 4B 2507 | 262k | 43 | **$0.00** | 0.0 | 0.00 |
| Qwen3 Coder 480B | 262k | 42 | **$3.00** | 42.3 | 1.56 |
| QwQ-32B | 131k | 38 | **$0.74** | 47.5 | 0.61 |
| Qwen3 30B 2507 | 262k | 37 | **$0.35** | 87.3 | 0.96 |
| Qwen3 Coder 30B | 262k | 33 | **$0.90** | 92.2 | 1.46 |

### ğŸŸ  Amazon
| Model ğŸ” | Context Window ğŸ“ | Intelligence ğŸ’¡ | Price ğŸ’° (USD/1M) | Speed âš¡ (Tokens/s) | Latency â±ï¸ (s) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| Nova Premier | 1m | 31 | **$5.00** | 74.4 | 0.88 |

### ğŸŸª Anthropic
| Model ğŸ” | Context Window ğŸ“ | Intelligence ğŸ’¡ | Price ğŸ’° (USD/1M) | Speed âš¡ (Tokens/s) | Latency â±ï¸ (s) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| Claude 4.1 Opus | 200k | 59 | **$30.00** | 46.3 | 1.55 |
| Claude 4 Sonnet | 1m | 57 | **$6.00** | 51.5 | 1.13 |
| Claude 4 Opus | 200k | 54 | **$30.00** | 52.2 | 1.57 |
| Claude 4.1 Opus | 200k | 45 | **$30.00** | 45.2 | 1.57 |
| Claude 4 Sonnet | 1m | 44 | **$6.00** | 76.2 | 1.25 |
| Claude 4 Opus | 200k | 42 | **$30.00** | 52.2 | 1.95 |

### ğŸ”¶ Cohere
| Model ğŸ” | Context Window ğŸ“ | Intelligence ğŸ’¡ | Price ğŸ’° (USD/1M) | Speed âš¡ (Tokens/s) | Latency â±ï¸ (s) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| Command A | 256k | 28 | **$4.38** | 94.0 | 0.18 |
| Aya Expanse 32B | 128k | 6 | **$0.75** | 69.5 | 0.12 |
| Aya Expanse 8B | 8k | 2 | **$0.75** | 81.0 | 0.19 |

### âš™ï¸ DeepSeek
| Model ğŸ” | Context Window ğŸ“ | Intelligence ğŸ’¡ | Price ğŸ’° (USD/1M) | Speed âš¡ (Tokens/s) | Latency â±ï¸ (s) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| DeepSeek V3.1 | 128k | 54 | **$0.96** | 20.1 | 2.89 |
| DeepSeek R1 0528 | 128k | 52 | **$0.96** | 20.5 | 2.84 |
| DeepSeek V3.1 | 128k | 45 | **$0.48** | 19.8 | 2.83 |
| DeepSeek R1 0528 Qwen3 8B | 33k | 35 | **$0.07** | 54.5 | 0.72 |

### ğŸ”µ Google
| Model ğŸ” | Context Window ğŸ“ | Intelligence ğŸ’¡ | Price ğŸ’° (USD/1M) | Speed âš¡ (Tokens/s) | Latency â±ï¸ (s) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| Gemini 2.5 Pro | 1m | 60 | **$3.44** | 152.9 | 28.39 |
| Gemini 2.5 Flash | 1m | 51 | **$0.85** | 255.7 | 11.28 |
| Gemini 2.5 Flash | 1m | 40 | **$0.85** | 227.9 | 0.31 |
| Gemini 2.5 Flash-Lite | 1m | 40 | **$0.17** | 540.3 | 7.69 |
| Gemini 2.5 Flash-Lite | 1m | 30 | **$0.17** | 352.3 | 0.23 |
| Gemma 3 27B | 128k | 22 | **$0.00** | 47.1 | 0.63 |
| Gemma 3 12B | 128k | 21 | **$0.23** | 0.0 | 0.00 |
| Gemma 3n E4B | 32k | 16 | **$0.03** | 72.9 | 0.33 |
| Gemma 3 4B | 128k | 15 | **$0.03** | 0.0 | 0.00 |
| Gemma 3n E2B | 32k | 8 | **$0.00** | 43.1 | 0.32 |
| Gemma 3 1B | 32k | 6 | **$0.00** | 0.0 | 0.00 |

### âšª IBM
| Model ğŸ” | Context Window ğŸ“ | Intelligence ğŸ’¡ | Price ğŸ’° (USD/1M) | Speed âš¡ (Tokens/s) | Latency â±ï¸ (s) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| Granite 3.3 8B | 128k | 15 | **$0.09** | 109.9 | 0.41 |

### ğŸ§© LG AI Research
| Model ğŸ” | Context Window ğŸ“ | Intelligence ğŸ’¡ | Price ğŸ’° (USD/1M) | Speed âš¡ (Tokens/s) | Latency â±ï¸ (s) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| EXAONE 4.0 32B | 131k | 43 | **$0.70** | 77.0 | 0.30 |
| EXAONE 4.0 32B | 131k | 33 | **$0.70** | 68.2 | 0.33 |
| Exaone 4.0 1.2B | 64k | 27 | **$0.00** | 0.0 | 0.00 |
| Exaone 4.0 1.2B | 64k | 20 | **$0.00** | 0.0 | 0.00 |

### ğŸ’§ Liquid AI
| Model ğŸ” | Context Window ğŸ“ | Intelligence ğŸ’¡ | Price ğŸ’° (USD/1M) | Speed âš¡ (Tokens/s) | Latency â±ï¸ (s) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| LFM2 1.2B | 33k | 8 | **$0.00** | 0.0 | 0.00 |

### ğŸ¦™ Meta
| Model ğŸ” | Context Window ğŸ“ | Intelligence ğŸ’¡ | Price ğŸ’° (USD/1M) | Speed âš¡ (Tokens/s) | Latency â±ï¸ (s) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| Llama 4 Maverick | 1m | 36 | **$0.39** | 143.8 | 0.34 |
| Llama 4 Scout | 10m | 28 | **$0.26** | 115.5 | 0.37 |
| Llama 3.3 70B | 128k | 28 | **$0.60** | 85.2 | 0.45 |
| Llama 3.1 405B | 128k | 26 | **$3.75** | 31.7 | 0.75 |
| Llama 3.2 90B (Vision) | 128k | 19 | **$0.72** | 30.5 | 0.37 |
| Llama 3.2 11B (Vision) | 128k | 15 | **$0.16** | 72.2 | 0.39 |

### ğŸ–¥ï¸ Microsoft Azure
| Model ğŸ” | Context Window ğŸ“ | Intelligence ğŸ’¡ | Price ğŸ’° (USD/1M) | Speed âš¡ (Tokens/s) | Latency â±ï¸ (s) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| Phi-4 | 16k | 25 | **$0.22** | 29.8 | 0.46 |
| Phi-4 Multimodal | 128k | 12 | **$0.00** | 18.2 | 0.36 |

### âš¡ MiniMax
| Model ğŸ” | Context Window ğŸ“ | Intelligence ğŸ’¡ | Price ğŸ’° (USD/1M) | Speed âš¡ (Tokens/s) | Latency â±ï¸ (s) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| MiniMax M1 80k | 1m | 46 | **$0.82** | 0.0 | 0.00 |
| MiniMax M1 40k | 1m | 42 | **$0.82** | 0.0 | 0.00 |
| MiniMax-Text-01 | 4m | 26 | **$0.42** | 0.0 | 0.00 |

### ğŸ”º Mistral
| Model ğŸ” | Context Window ğŸ“ | Intelligence ğŸ’¡ | Price ğŸ’° (USD/1M) | Speed âš¡ (Tokens/s) | Latency â±ï¸ (s) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| Mistral Medium 3.1 | 128k | 35 | **$0.80** | 48.8 | 0.41 |
| Mistral Medium 3 | 128k | 35 | **$0.80** | 67.7 | 0.43 |
| Magistral Medium | 40k | 34 | **$2.75** | 144.2 | 0.39 |
| Magistral Small | 40k | 32 | **$0.75** | 179.6 | 0.32 |
| Mistral Small 3.2 | 128k | 29 | **$0.15** | 144.5 | 0.28 |
| Devstral Medium | 256k | 28 | **$0.80** | 101.1 | 0.38 |
| Devstral Small | 256k | 18 | **$0.15** | 145.4 | 0.33 |
| Codestral (Jan) | 256k | 13 | **$0.45** | 152.6 | 0.30 |
| Ministral 8B | 128k | 8 | **$0.10** | 175.8 | 0.30 |
| Ministral 3B | 128k | 5 | **$0.04** | 248.1 | 0.29 |

### ğŸŒ™ Moonshot AI
| Model ğŸ” | Context Window ğŸ“ | Intelligence ğŸ’¡ | Price ğŸ’° (USD/1M) | Speed âš¡ (Tokens/s) | Latency â±ï¸ (s) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| Kimi K2 0905 | 256k | 50 | **$1.35** | 55.1 | 0.48 |
| Kimi K2 | 128k | 48 | **$1.07** | 54.1 | 0.50 |

### ğŸ§  Nous Research
| Model ğŸ” | Context Window ğŸ“ | Intelligence ğŸ’¡ | Price ğŸ’° (USD/1M) | Speed âš¡ (Tokens/s) | Latency â±ï¸ (s) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| Hermes 4 - Llama-3.1 70B | 128k | 39 | **$0.20** | 82.8 | 0.59 |
| Hermes 4 405B | 128k | 33 | **$1.50** | 31.9 | 0.70 |
| Hermes 4 70B | 128k | 24 | **$0.20** | 75.7 | 0.58 |
| DeepHermes 3 - Mistral 24B | 32k | 16 | **$0.00** | 0.0 | 0.00 |
| DeepHermes 3 - Llama-3.1 8B | 128k | 2 | **$0.00** | 0.0 | 0.00 |

### ğŸŸ© NVIDIA
| Model ğŸ” | Context Window ğŸ“ | Intelligence ğŸ’¡ | Price ğŸ’° (USD/1M) | Speed âš¡ (Tokens/s) | Latency â±ï¸ (s) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| Llama Nemotron Super 49B v1.5 | 128k | 45 | **$0.00** | 0.0 | 0.00 |
| Llama Nemotron Ultra | 128k | 38 | **$0.90** | 37.5 | 0.71 |
| NVIDIA Nemotron Nano 9B V2 | 131k | 38 | **$0.00** | 0.0 | 0.00 |
| NVIDIA Nemotron Nano 9B V2 | 131k | 37 | **$0.00** | 0.0 | 0.00 |
| Llama 3.3 Nemotron Super 49B | 128k | 35 | **$0.00** | 0.0 | 0.00 |
| Llama Nemotron Super 49B v1.5 | 128k | 27 | **$0.00** | 0.0 | 0.00 |
| Llama 3.1 Nemotron Nano 4B v1.1 | 128k | 26 | **$0.00** | 0.0 | 0.00 |
| Llama 3.3 Nemotron Super 49B v1 | 128k | 26 | **$0.00** | 0.0 | 0.00 |
| Llama 3.1 Nemotron 70B | 128k | 23 | **$0.17** | 32.2 | 0.56 |

### ğŸ§­ OpenAI
| Model ğŸ” | Context Window ğŸ“ | Intelligence ğŸ’¡ | Price ğŸ’° (USD/1M) | Speed âš¡ (Tokens/s) | Latency â±ï¸ (s) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| GPT-5 (high) | 400k | 67 | **$3.44** | 61.9 | 72.53 |
| GPT-5 (medium) | 400k | 66 | **$3.44** | 177.3 | 30.76 |
| o3-pro | 200k | 65 | **$35.00** | 20.1 | 127.04 |
| o3 | 200k | 65 | **$3.50** | 187.1 | 12.32 |
| GPT-5 mini (high) | 400k | 62 | **$0.69** | 76.7 | 99.19 |
| GPT-5 (low) | 400k | 62 | **$3.44** | 150.9 | 14.41 |
| GPT-5 mini (medium) | 400k | 61 | **$0.69** | 73.7 | 27.82 |
| o4-mini (high) | 200k | 59 | **$1.93** | 107.9 | 39.30 |
| gpt-oss-120B (high) | 131k | 58 | **$0.26** | 226.5 | 0.44 |
| o3-mini (high) | 200k | 51 | **$1.93** | 141.7 | 41.54 |
| GPT-5 nano (high) | 400k | 49 | **$0.14** | 122.8 | 67.06 |
| o3-mini | 200k | 48 | **$1.93** | 149.3 | 12.46 |
| GPT-5 nano (medium) | 400k | 48 | **$0.14** | 196.2 | 31.93 |
| gpt-oss-20B (high) | 131k | 45 | **$0.09** | 255.5 | 0.52 |
| GPT-5 (minimal) | 400k | 43 | **$3.44** | 134.0 | 1.05 |
| GPT-4.1 | 1m | 43 | **$3.50** | 105.5 | 0.51 |
| GPT-4.1 mini | 1m | 42 | **$0.70** | 70.5 | 0.45 |
| GPT-5 mini (minimal) | 400k | 42 | **$0.69** | 73.1 | 0.98 |
| GPT-5 nano (minimal) | 400k | 29 | **$0.14** | 209.0 | 0.85 |
| GPT-4.1 nano | 1m | 27 | **$0.17** | 108.5 | 0.40 |
| GPT-4o (ChatGPT) | 128k | 25 | **$7.50** | 0.0 | 0.00 |
| GPT-4o mini | 128k | 21 | **$0.26** | 62.1 | 0.52 |

### ğŸŒ€ Perplexity
| Model ğŸ” | Context Window ğŸ“ | Intelligence ğŸ’¡ | Price ğŸ’° (USD/1M) | Speed âš¡ (Tokens/s) | Latency â±ï¸ (s) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| R1 1776 | 128k | 19 | **$3.50** | 0.0 | 0.00 |

### ğŸ”¶ Reka AI
| Model ğŸ” | Context Window ğŸ“ | Intelligence ğŸ’¡ | Price ğŸ’° (USD/1M) | Speed âš¡ (Tokens/s) | Latency â±ï¸ (s) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| Reka Flash 3 | 128k | 33 | **$0.35** | 50.9 | 1.31 |

### â˜€ï¸ Upstage
| Model ğŸ” | Context Window ğŸ“ | Intelligence ğŸ’¡ | Price ğŸ’° (USD/1M) | Speed âš¡ (Tokens/s) | Latency â±ï¸ (s) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| Solar Pro 2 | 66k | 38 | **$0.50** | 104.3 | 1.39 |
| Solar Pro 2 | 66k | 30 | **$0.50** | 107.1 | 1.39 |

### âš¡ xAI
| Model ğŸ” | Context Window ğŸ“ | Intelligence ğŸ’¡ | Price ğŸ’° (USD/1M) | Speed âš¡ (Tokens/s) | Latency â±ï¸ (s) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| Grok 4 | 256k | 65 | **$6.00** | 49.0 | 11.64 |
| Grok 3 mini Reasoning (high) | 1m | 57 | **$0.35** | 99.3 | 0.61 |
| Grok Code Fast 1 | 256k | 49 | **$0.53** | 300.3 | 6.49 |
| Grok 3 Reasoning Beta | 1m | 41 | **$0.00** | 0.0 | 0.00 |
| Grok 3 | 1m | 36 | **$6.00** | 51.3 | 0.69 |
| Grok 3 mini Reasoning (low) | 1m | â€” | **$0.35** | 62.0 | 0.57 |

### ğŸ§¾ Z AI
| Model ğŸ” | Context Window ğŸ“ | Intelligence ğŸ’¡ | Price ğŸ’° (USD/1M) | Speed âš¡ (Tokens/s) | Latency â±ï¸ (s) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| GLM-4.5 | 128k | 49 | **$0.97** | 57.5 | 0.65 |
| GLM-4.5-Air | 128k | 48 | **$0.42** | 99.8 | 0.98 |
| GLM-4.5V | 64k | 39 | **$0.90** | 94.8 | 0.78 |
| GLM-4.5V | 64k | 26 | **$0.90** | 88.5 | 0.70 |
